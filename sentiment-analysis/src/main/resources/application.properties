# Use Phi-3 Mini, a small and capable LLM from Ollama Hub
quarkus.langchain4j.ollama.chat-model.model-id=phi3:mini

# Increase timeout for initial model loading
quarkus.langchain4j.ollama.timeout=120s
